{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "531dd188",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning Day07\n",
    "\n",
    "This capability is provided in the GridSearchCV class and can eb used to discover the ebst way to configure the model for top performance on the system\n",
    "\n",
    "For example, we can define q grid of the number of trees (n_estimators) and tree siozes(max_depth) to evaluate by defining the grid asL\n",
    "\n",
    "n_estimators = [50, 100, 150, 200]\n",
    "max_depth = [2,4,6,8]\n",
    "param_grid = dict(max_depth=max_depth, n_estimators=n_estimators)\n",
    "And then evaluate each combination of parameters using 10-fold cross validation\n",
    "\n",
    "Stratified k fold: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=7)\n",
    "grid_search - GridSerachCV(model, param_grid, scoring=\"neg_log_loss\", n_jobs=-1, cv=kfold, verbose=1)\n",
    "result = grid_search.fit(X, label_encoded_Y)\n",
    "We can then review the results to determine the best combination and the general trendsa in varying the combination of parameters.\n",
    "\n",
    "This is the best practise when applying XGBoost tto your own problems. The parameters to consider tuning are:\n",
    "\n",
    "1) The number and the size of the trees (n_estimators, max_depth)\n",
    "\n",
    "2) The learning rate and the number of trees (laarning_rate and n_estimators)\n",
    "\n",
    "3) The row and the column subsampling rates\n",
    "\n",
    "Here we consider an example of just tuning the learning rate\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b0272cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tunning the learning rate\n",
    "\n",
    "from numpy import loadtxt\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d84a2b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the data\n",
    "dataset = loadtxt('pima-indians-diabetes.csv', delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "681dc1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the data into X and y\n",
    "\n",
    "X = dataset[:, 0:8]\n",
    "y = dataset[:,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "457fe8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#grid search\n",
    "model = XGBClassifier()\n",
    "learning_rate = [0.0001, 0.001, 0.01, 0.1, 0.2, 0.3]\n",
    "param_grid = dict(learning_rate=learning_rate)\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=7)\n",
    "grid_search = GridSearchCV(model, param_grid, scoring='neg_log_loss', n_jobs=1, cv=kfold)\n",
    "grid_result = grid_search.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ec46267f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: -0.530152 using {'learning_rate': 0.01}\n",
      "-0.689563 (0.000760) with: {'learning_rate': 0.0001}\n",
      "-0.660868 (0.006202) with: {'learning_rate': 0.001}\n",
      "-0.530152 (0.034452) with: {'learning_rate': 0.01}\n",
      "-0.552723 (0.117636) with: {'learning_rate': 0.1}\n",
      "-0.653341 (0.171609) with: {'learning_rate': 0.2}\n",
      "-0.718789 (0.176641) with: {'learning_rate': 0.3}\n"
     ]
    }
   ],
   "source": [
    "#summarize the results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
